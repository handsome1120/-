{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "安裝需要的套件\n",
        "langchain：基本的langchain套件\n",
        "openai：基本的openai套件\n",
        "unstructured：讀取文字檔格式的套件\n",
        "chromadb：向量儲存資料庫\n",
        "tiktoken套件：OpenAI算token數的套件"
      ],
      "metadata": {
        "id": "aqUbk76TFjIL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3houcJQFhoY"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "# !pip install openai\n",
        "!pip install langchain-openai\n",
        "!pip install unstructured\n",
        "!pip install chromadb\n",
        "!pip install tiktoken\n",
        "!pip install tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "將環境變數讀入"
      ],
      "metadata": {
        "id": "h8xttXXWFnQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 導入 ColabSecrets 用戶資料模組\n",
        "from google.colab import userdata\n",
        "\n",
        "# 設置 OpenAI API key\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "6wlj1aHdForw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "先套用OpenAI的API\n",
        "使用langchain中的OpenAI套件載入大型語言模型，載入OpenAi模型，並且設定最大輸出長度為1024。此部分會收費"
      ],
      "metadata": {
        "id": "O1sWpRC1Fp7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=512,\n",
        "    )"
      ],
      "metadata": {
        "id": "FKF1wrEgFrLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "測試沒有RAG時候的問答"
      ],
      "metadata": {
        "id": "6zxAgQfYFsOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"工專時期第3任校長是誰?\")"
      ],
      "metadata": {
        "id": "SiKVhsi6FtQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"明新科技大學的校訓是什麼?\")"
      ],
      "metadata": {
        "id": "XbLPidqQFuf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/zzxx666413/LLM_RAG20240510/master/must.txt"
      ],
      "metadata": {
        "id": "iqUHen5iF2pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/zzxx666413/LLM_RAG20240510/master/2028%E7%B8%BD%E7%B5%B1%E5%80%99%E9%81%B8%E4%BA%BA.txt"
      ],
      "metadata": {
        "id": "oaeNI7ZqF3-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立本機知識庫QA機器人\n",
        "Document loaders"
      ],
      "metadata": {
        "id": "pqVH1XIpF5LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain import OpenAI,VectorDBQA\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "# 載入資料夾中所有TXT檔案\n",
        "loader = DirectoryLoader('/content/', glob='**/*.txt')\n",
        "\n",
        "# 將資料轉成document物佚，每個檔案會為作為一個document\n",
        "documents = loader.load()\n",
        "\n",
        "# 初始化載入器\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "\n",
        "# 切割加载的 document\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# 初始化 openai 的 embeddings 物件\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# 將 document 透過 openai 的 embeddings 物件計算 embedding向量資料暫時存入 Chroma 向量資料庫用於後續的搜尋\n",
        "docsearch = Chroma.from_documents(split_docs, embeddings)\n",
        "\n",
        "# 建立回答物件\n",
        "qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch, return_source_documents=True)\n",
        "\n",
        "# 進行回答\n",
        "result = qa({\"query\": \"工專時期第3任校長是誰?\"})\n",
        "print(result['result'])"
      ],
      "metadata": {
        "id": "KAenuGKHF6fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa({\"query\": \"現行明新科技大學之校訓?\"})\n",
        "print(result['result'])"
      ],
      "metadata": {
        "id": "upWxoqCnF74e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "現行明新科技大學之校訓為「堅毅、求新、創造」。\n",
        "文件分割器的chunk_overlap參數，切分後每個文件裡包含幾個上一個文件結尾的內容，主要作用是為了增加每個文件的上下文關聯。比如chunk_overlap=0時，第一個文件為aaaaaa，第二個為bbbbbb；當chunk_overlap=2時，第一個文件為aaaaaa，第二個為aabbbbbb。\n",
        "\n",
        "替模型加入記憶功能\n",
        "「對話記憶體」（ConversationBufferMemory）用於儲存簡單的對話歷史\n",
        "ConversationBufferMemory\n",
        "memory_management"
      ],
      "metadata": {
        "id": "TJKcZ2S7F9Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# 建立記憶體實例，開啟 return_messages 是為了將記憶體指定給 chat模型\n",
        "# 而 memory_key則是可以讓我們客制我們取得對話記錄時用的 key 值\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# 建立 chat 語言模型\n",
        "# llm_chat = ChatOpenAI()\n",
        "\n",
        "# 提示設計\n",
        "prompt_chat = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        SystemMessagePromptTemplate.from_template(\n",
        "            \"你是一個友善的學習助理，你接下來會跟使用者來對話。\"\n",
        "        ),\n",
        "        # 這裏是一個讓記憶體資料填空的地方。\n",
        "        # 我們也要設定，使用chat_history 來取得對話記錄\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "conversation_chat = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt_chat,\n",
        "    verbose=True,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "1T53JgoBF_Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chat({\n",
        "    'question': '你好'\n",
        "})"
      ],
      "metadata": {
        "id": "Hh10icJhGAZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chat({\n",
        "    'question': '你可以告訴我英國和美國的首都在哪裡嗎?'\n",
        "})"
      ],
      "metadata": {
        "id": "DT9s6RmdGBwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#查詢記憶內容\n",
        "print(\"chat_history:\", memory.load_memory_variables({}))"
      ],
      "metadata": {
        "id": "DJ0O6JhDGDVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "進階記憶功能\n",
        "ConversationBufferWindowMemory 類別\n",
        "直譯為「局部窗口對話記憶體」。它的主要功能是限制在一個局部窗口內保存的對話資訊。由於 token 的運算資源有限且需消耗費用，甚至如果語言模型是我們自己架設的，同樣需要大量的運算資源，因此我們不能讓歷史對話資料無窮無盡地累積。\n",
        "\n",
        "使用ConversationBufferWindowMemory 類別，可以只保存最近的 k 條訊息。"
      ],
      "metadata": {
        "id": "ElJJ2fF8GEol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "# 建立 ConversationBufferWindowMemory 實例, k=1 即限制一條訊息\n",
        "memory_buffer_window = ConversationBufferWindowMemory(k=1)\n",
        "\n",
        "# 更新上下文資訊\n",
        "memory_buffer_window.save_context({\"input\": \"你好！\"}, {\"output\": \"什麼事？\"})\n",
        "memory_buffer_window.save_context({\"input\": \"今天天氣真好！\"}, {\"output\": \"我覺得太熱了！\"})\n",
        "memory_buffer_window.save_context({\"input\": \"這是最新的訊息\"}, {\"output\": \"只會記錄這個訊息！\"})\n",
        "# 取得記憶體內儲存的資訊\n",
        "memory_buffer_window.load_memory_variables({})\n",
        "\n",
        "#--- 實際的輸出 ---\n",
        "\n",
        "# {'history': 'Human: 這是最新的訊息\\nAI: 只會記錄這個訊息！'}"
      ],
      "metadata": {
        "id": "_P36XLJFGF21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 下方是建立向量資料庫的部分\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.memory import VectorStoreRetrieverMemory\n",
        "\n",
        "db_chroma = Chroma(embedding_function=OpenAIEmbeddings())\n",
        "\n",
        "retriever = db_chroma.as_retriever(search_kwargs=dict(k=1))\n",
        "\n",
        "memory_vs = VectorStoreRetrieverMemory(retriever=retriever, return_messages=True)\n",
        "\n",
        "# 這裏是模擬我們已經有三個對話記錄\n",
        "memory_vs.save_context({\"Human\": \"我最喜歡的食物是披薩\"}, {\"AI\": \"這樣很棒！\"})\n",
        "memory_vs.save_context({\"Human\": \"我最喜歡的運動是游泳\"}, {\"AI\": \"很高興你跟我說分享你的嗜好。\"})\n",
        "memory_vs.save_context({\"Human\": \"我不喜歡上班\"}, {\"AI\": \"瞭解\"})\n",
        "memory_vs.save_context({\"Human\": \"奇奇自助餐很貴\"}, {\"AI\": \"太糟糕了\"})\n",
        "\n",
        "# 使用 load_memory_varialbes 取得使用者問題相似度的歷史資料\n",
        "print(memory_vs.load_memory_variables({\"prompt\": \"我該看什麼運動節目？\"}))\n",
        "# print(memory_vs.load_memory_variables({\"prompt\": \"昂貴的店家\"}))"
      ],
      "metadata": {
        "id": "CZ6N1ijGGHL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "整合\n",
        "Chain類別"
      ],
      "metadata": {
        "id": "iELS6fs6GIZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import VectorStoreRetrieverMemory\n",
        "\n",
        "# 載入資料夾中所有TXT檔案\n",
        "loader = DirectoryLoader('/content/', glob='**/*.txt')\n",
        "\n",
        "# 將資料轉成document物佚，每個檔案會為作為一個document\n",
        "documents = loader.load()\n",
        "\n",
        "# 初始化載入器\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "\n",
        "# 切割加载的 document\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# 初始化 openai 的 embeddings 物件\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# 將 document 透過 openai 的 embeddings 物件計算 embedding向量資料暫時存入 Chroma 向量資料庫用於後續的搜尋\n",
        "\n",
        "docsearch = Chroma.from_documents(split_docs, embeddings)\n",
        "\n",
        "# 建立檢索器\n",
        "retriever = docsearch.as_retriever()\n",
        "\n",
        "# 建立記憶體\n",
        "memory_vs = VectorStoreRetrieverMemory(retriever=retriever, return_messages=True)\n",
        "\n",
        "# 設置預設的prompt\n",
        "DEFAULT_TEMPLATE = \"\"\"\n",
        "你是一個友善的對話機器人，下面歷史記錄是我們曾經的對話。\n",
        "Human 是我，AI 是你。請根據歷史記錄中的資訊來回覆我的新問題。\n",
        "\n",
        "歷史記錄:\n",
        "{history}\n",
        "\n",
        "Human：{input}\n",
        "AI：\n",
        "\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=DEFAULT_TEMPLATE\n",
        ")\n",
        "conversation_with_memory_vs = ConversationChain(\n",
        "    llm=llm,\n",
        "    prompt=PROMPT,\n",
        "    memory=memory_vs,\n",
        "    # verbose=True,\n",
        "    output_key='AI'\n",
        ")"
      ],
      "metadata": {
        "id": "PHVWAihoGJ0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_memory_vs.predict(input=\"2028總統候選人有誰?\")"
      ],
      "metadata": {
        "id": "pygyLtYhGLBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_memory_vs.predict(input=\"我的名字叫做Kevin，很高興認識你\")"
      ],
      "metadata": {
        "id": "JjeXDtE-GMOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_memory_vs.predict(input=\"你還記得我叫什麼名字嗎?\")"
      ],
      "metadata": {
        "id": "02QT-ICVGNbV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}