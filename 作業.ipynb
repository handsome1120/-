{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFQ1zZDiaxVy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "查看GPU"
      ],
      "metadata": {
        "id": "97ofqU9Ya5gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRJq1O4ba6No",
        "outputId": "2be85688-3bf8-4d44-ba4e-6a9b51d07077"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安裝需要的BERT套件"
      ],
      "metadata": {
        "id": "CgXcgHYCbSKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.29.0 -U\n",
        "!pip install nlp -U\n",
        "!pip install torch==2.0.0 -U\n",
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "id": "3gc6N47pbSjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "載入套件"
      ],
      "metadata": {
        "id": "A-dKg8rpbUNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments\n",
        "from nlp import load_dataset, Dataset\n",
        "import nlp\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "DfFHhmmAbWZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "抓取訓練資料"
      ],
      "metadata": {
        "id": "kQvmHNKMbYCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/shhuangmust/AI/raw/112-1/train.csv"
      ],
      "metadata": {
        "id": "wk_5fj-ebZRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "讀取訓練資料集"
      ],
      "metadata": {
        "id": "b1HjmSdcbdSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "_m7ijipJbfJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "id": "AHqu3RCDbgi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "載入原始模型"
      ],
      "metadata": {
        "id": "vIO1EwVXblQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('hfl/chinese-bert-wwm-ext')"
      ],
      "metadata": {
        "id": "jV0nqZVvblkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "載入分詞模型"
      ],
      "metadata": {
        "id": "Q_V3RK0KbnzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('hfl/chinese-bert-wwm-ext')"
      ],
      "metadata": {
        "id": "xZL2zBphbo7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "設定執行參數"
      ],
      "metadata": {
        "id": "BFNRHxbFbpyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 5\n",
        "MAX_LEN = 512\n",
        "EPOCHS=5\n",
        "BATCH_SIZE = 8"
      ],
      "metadata": {
        "id": "IbvScQotbqzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "把資料集分成訓練、測試、驗證"
      ],
      "metadata": {
        "id": "rqk_xCq-br01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_ds = dataset.shuffle(RANDOM_SEED)\n",
        "split_ds = shuffled_ds.train_test_split(test_size=0.2)\n",
        "train_dataset = split_ds['train']\n",
        "test_val_dataset = split_ds['test']\n",
        "split_tv = test_val_dataset.train_test_split(test_size=0.5)\n",
        "test_dataset = split_tv['train']\n",
        "val_dataset = split_tv['test']"
      ],
      "metadata": {
        "id": "TPVKx4P4btuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "取一筆出來瞧瞧(已經打亂)"
      ],
      "metadata": {
        "id": "L71BCh5ubv6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[2]"
      ],
      "metadata": {
        "id": "eh0K8KTkbxIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(\"體重跟體脂都有在持續緩慢的下降中\")"
      ],
      "metadata": {
        "id": "IaNb0vS9bzEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定義分詞器"
      ],
      "metadata": {
        "id": "imtcei-ib0lG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch['Description'], max_length=MAX_LEN, padding=True, truncation=True)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
        "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
        "val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
        "\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
      ],
      "metadata": {
        "id": "b7m6drnzb1lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定義評測準則，訓練器"
      ],
      "metadata": {
        "id": "GkR-DwQxb2s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.01,\n",
        "    # evaluate_during_training=True,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")"
      ],
      "metadata": {
        "id": "XUo-e9EDb34A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "開始訓練"
      ],
      "metadata": {
        "id": "cRw1UsKmb8CA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oSrZgC3Mb886"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "B69NwFqvb9zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "找一個範例來測試"
      ],
      "metadata": {
        "id": "moNUyx7eb_TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.iloc[220]['label'], df.iloc[220]['Description'])\n",
        "print(df.iloc[578]['label'], df.iloc[578]['Description'])"
      ],
      "metadata": {
        "id": "NHnt1GcbcAWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "設定測試文字"
      ],
      "metadata": {
        "id": "tJpeZOWecBbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_text = '增強免疫力...護眼明目...抗氧化...保肝...皮膚：...保護皮膚，減緩皮屑問題，降低敏感...毛髮……促進毛髮亮麗...消化系統」「強化免疫系統，有助調整過敏體質...清除自由基延緩老化...調整腸胃道機能...調理皮膚問題...諾麗果含有許多強大的抗氧化劑」「阻止或減少病痛的發生，並迅速修補已受傷的細胞，將代謝殘渣或毒素排出體外」「它能維護身體細胞組織正常運作，阻止或減少病痛的發生，並迅速修補已受傷的細胞，將代謝殘渣或毒素排出體外，使身體恢復正常'\n",
        "test_text = '???????每份含有30mg輔Q10。輔Q10可參與維生素E再生，兩者具協同作用，可促進新陳代謝。保護循環順暢維持健康。暢銷日本的最佳美容聖品'\n",
        "\n",
        "MAX_LEN = 512\n",
        "\n",
        "encoded_review = tokenizer.encode_plus(\n",
        "    test_text,\n",
        "    max_length=MAX_LEN,\n",
        "    add_special_tokens=True,\n",
        "    return_token_type_ids=False,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "7MaZoJ9ncChc",
        "outputId": "88bb8303-0b9f-4c71-f9c8-efab2aea5be0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1f017d7323f4>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMAX_LEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m encoded_review = tokenizer.encode_plus(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "zuaEBjqfcES6",
        "outputId": "971c4069-bd26-4c5c-dc7e-1adc8975fbd8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'encoded_review' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-aa08110a8449>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoded_review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'encoded_review' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "進行測試"
      ],
      "metadata": {
        "id": "GDrWWxq4cFZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = model.to('cuda')\n",
        "\n",
        "input_ids = encoded_review['input_ids'].to('cuda')\n",
        "attention_mask = encoded_review['attention_mask'].to('cuda')\n",
        "output = test_model(input_ids, attention_mask)\n",
        "result = torch.argmax(output[0][0])\n",
        "\n",
        "classnames = ['合格', '不合格']\n",
        "\n",
        "print(f'廣告詞: {test_text}')\n",
        "print(f'檢測結果: {classnames[result]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Lkv2mn0DcGsa",
        "outputId": "0198475e-8397-4452-f2a6-553a940ac927"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-70e9e73a366f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_review\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_review\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}