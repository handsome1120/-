{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "編碼器模型範例\n",
        "這是一個編碼器模型的範例，用於將輸入的序列進行編碼，並將編碼後的結果輸出。"
      ],
      "metadata": {
        "id": "tfouIrIUCYcx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkUNh7q1CWeG"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer,BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "text=\"my bank account\"\n",
        "encoded_input = tokenizer(text, max_length=100,\n",
        "         add_special_tokens=True, truncation=True,\n",
        "         padding=True, return_tensors=\"pt\")\n",
        "output = model(**encoded_input)\n",
        "print(output[0].shape)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "解碼器"
      ],
      "metadata": {
        "id": "omxXHOsUCcOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, GPT2Model\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "model = GPT2Model.from_pretrained(\"openai-community/gpt2\")\n",
        "\n",
        "inputs = tokenizer(\"Yes, Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "print(last_hidden_states.shape)\n",
        "#print(model)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "Q9MgHXZKCdXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "# 加載預訓練的GPT-2模型（帶有語言模型頭部的版本）和分詞器\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# 準備輸入文字\n",
        "text = \"The quick brown fox jumps over the lazy dog\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# 獲取模型輸出\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# logits 是應用softmax之前的輸出，直接對應於詞彙表的維度\n",
        "logits = outputs.logits\n",
        "\n",
        "# 展示logits的維度\n",
        "# 維度應該是 [批次大小, 序列長度, 詞彙表大小]\n",
        "print(\"Logits shape:\", logits.shape)"
      ],
      "metadata": {
        "id": "YDfB9yRPCfA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "序列到序列"
      ],
      "metadata": {
        "id": "hX091zASCgRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MT5EncoderModel, T5Tokenizer\n",
        "\n",
        "# 加載模型和分詞器\n",
        "model_name = 'google/mt5-small' # 可以根據需要選擇不同大小的MT5模型\n",
        "model = MT5EncoderModel.from_pretrained(model_name)\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "UYHQOJRhChcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "偏見及問題"
      ],
      "metadata": {
        "id": "siHiGXTcCoKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "result = unmasker(\"This man works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"This woman works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ],
      "metadata": {
        "id": "DpgfH51YCpRx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}